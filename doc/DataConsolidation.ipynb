{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data consolidation\n",
    "Big task: Move all the development data sources that have been tried so far to ``AngrySnail`` aka ``BrashTapir``, stack 'em, format them, resample and reindex and stuff it all into a couple of HDF5 files for archiving. Then clean those up with pck tool from pytables. Plot, and shove png to ``BuddingSepiida``.\n",
    "\n",
    "## Data sources\n",
    "\n",
    "So far only two nodes. Bed, and chuck.\n",
    "\n",
    "### Bed\n",
    "\n",
    "Recorded initially on ``ToastyTamandua``, now on ``RandyDolphin``\n",
    "* markI.csv\n",
    "* markII.csv\n",
    "* bed.csv\n",
    "* bed_2016-03-26.csv\n",
    "* 2016_w13-bed.csv\n",
    "\n",
    "### Chuck\n",
    "\n",
    "Recorded in ``VersedSquid``. Has some sensor ids in the sqlite database that should be taken into consideration when building codes for categorical columns when converting sensor string name into an integer id.\n",
    "\n",
    "Initial data needs to be resampled to something reasonable. Originally data was sampled in 1 s intervals. Downsampling to 1 min should be good and in line with how new sampling works.\n",
    "\n",
    "* telemetry.db\n",
    "* chuck_2016-03-28.csv\n",
    "* 2016_w13-chuck.csv\n",
    "\n",
    "## Reference format\n",
    "\n",
    "Simple three column structure\n",
    "\n",
    "    timestamp (unix[s], datetime64[ns]) | sensor_id (int) | value (float)\n",
    "    \n",
    "## TBD\n",
    "\n",
    "- Store values as float16 or float32? See [precision of float16](https://en.wikipedia.org/wiki/Half-precision_floating-point_format#Precision_limitations_on_other_decimal_values). I'd save ~6 Bytes, uncompressed, vs. storing double. Worst case for raw arduino values is +-0.5 on 512+. Not bad. But with storing at least 32 bit I lose a lot less information, at 2 B/row cost, and I'm future proof for higher range input without needed to normalize.\n",
    "    * **NEVERMIND:** Resampling with bfill or ffill does not work for float16. :D\n",
    "- storage format of sensor_id table (JSON, HDF5 meta data?)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import time\n",
    "from datetime import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mpl_lines\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "DTYPE_VAL = np.float32\n",
    "DTYPE_CAT = np.uint8\n",
    "FS_VAL = '1min'\n",
    "nodes = {'chuck': 0, 'bed': 1}\n",
    "sensors = {0: {'temp': 1, 'light': 2, 'soil':3, 'dummy': 4, 'ds_temp':5},\n",
    "           1: {'strain': 6, 'temp': 7, 'motion': 8}}\n",
    "# needed because of the naming overlap in the sensors. [b/c]x are placeholders for debugging.\n",
    "cats = {0: ['c0', 'temp', 'light', 'soil', 'c4', 'ds_temp', 'c6',  'c7'],\n",
    "        1: ['b0', 'b1', 'b2', 'b3', 'b4', 'b5', 'strain',  'temp',  'motion']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B1 markI.csv\n",
    "    * strain sensor only\n",
    "    * no header, two data columns (min, max) per timestamp\n",
    "    \n",
    "--> **only a few hours of noisy, high-Fs baseline. I'd say I leave this one out**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 7.03 ms per loop\n",
      "                     nid  sid  value\n",
      "timestamp                           \n",
      "2016-03-11 20:56:00    1    6  466.0\n",
      "2016-03-11 20:57:00    1    6  470.0\n",
      "2016-03-11 20:58:00    1    6  470.5\n"
     ]
    }
   ],
   "source": [
    "def load_b1(fpath='../local/db/consolidation/markI.csv', nid=1):\n",
    "    df = pd.read_csv(fpath, names=['timestamp', 'wmin', 'wmax'],\n",
    "                     dtype={'timestamp': np.float64, 'wmin': DTYPE_VAL, 'wmax': DTYPE_VAL})\n",
    "    df.set_index(df.timestamp.multiply(1e9).astype('datetime64[ns]'), inplace=True)\n",
    "\n",
    "    df = pd.DataFrame({'sid': sensors[nid]['strain'], 'nid': 1,\n",
    "                       'value': df[[\"wmin\", \"wmax\"]].mean(axis=1).resample(FS_VAL).ffill()})\n",
    "    return df\n",
    "\n",
    "%timeit load_b1()\n",
    "print load_b1().tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B2 markII.csv\n",
    "    * !! INVALID CHARACTERS !!\n",
    "    * same as markI.csv\n",
    "    * no header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 3: 42.1 ms per loop\n",
      "                     nid  sid  value\n",
      "timestamp                           \n",
      "2016-03-16 22:06:00    1    6  487.5\n",
      "2016-03-16 22:07:00    1    6  488.5\n",
      "2016-03-16 22:08:00    1    6  488.5\n"
     ]
    }
   ],
   "source": [
    "def load_b2(fpath='../local/db/consolidation/markII.csv', nid=1):\n",
    "    df = pd.read_csv(fpath, names=['timestamp', 'wmin', 'wmax'],\n",
    "                     dtype={'timestamp': np.float64, 'wmin': DTYPE_VAL, 'wmax': DTYPE_VAL})\n",
    "    df.set_index(df.timestamp.multiply(1e9).astype('datetime64[ns]'), inplace=True)\n",
    "    \n",
    "    df = pd.DataFrame({'sid': sensors[nid]['strain'],\n",
    "                       'nid': nid,\n",
    "                       'value': df[[\"wmin\", \"wmax\"]].mean(axis=1).resample(FS_VAL).ffill()})\n",
    "    return df\n",
    "\n",
    "%timeit load_b2()\n",
    "print load_b2().tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B3 bed.csv\n",
    "    * strain min and max as sensor type (strain_hi, strain_lo)\n",
    "    * added temp\n",
    "    * no header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 3: 64.9 ms per loop\n",
      "                     nid  sid       value\n",
      "timestamp                                \n",
      "2016-03-25 22:42:00    1    6  482.149994\n",
      "2016-03-25 22:43:00    1    6  482.200012\n",
      "2016-03-25 22:44:00    1    6  481.500000\n"
     ]
    }
   ],
   "source": [
    "def load_b3(fpath='../local/db/consolidation/bed.csv', nid=1):\n",
    "    df = pd.read_csv(fpath, names=['timestamp', 'sensor_str', 'value'],\n",
    "                     dtype={'timestamp': np.float64, 'sensor_str': str, 'value': DTYPE_VAL})\n",
    "    df.set_index(df.timestamp.multiply(1e9).astype('datetime64[ns]'), inplace=True)\n",
    "\n",
    "    temp = df.value.loc[df.sensor_str == 'temp'].resample(FS_VAL).ffill()\n",
    "    strain = pd.concat([df.value.loc[df.sensor_str == 'strain_hi'],\n",
    "                        df.value.loc[df.sensor_str == 'strain_lo']],\n",
    "                        axis=1).mean(axis=1).resample(FS_VAL).ffill()\n",
    "    df =  pd.concat([pd.DataFrame({'sid': sensors[nid]['temp'],\n",
    "                                   'nid': nid,\n",
    "                                   'value': temp}),\n",
    "                     pd.DataFrame({'sid': sensors[nid]['strain'],\n",
    "                                   'nid': nid,\n",
    "                                   'value': strain})])\n",
    "    return df\n",
    "\n",
    "%timeit load_b3()\n",
    "print load_b3().tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B4 bed_2016-03-26.csv\n",
    "    * added binary motion events\n",
    "    * simple strain values, 5s averages\n",
    "    * no header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 3: 24.7 ms per loop\n",
      "                               nid  sid  value\n",
      "timestamp                                     \n",
      "2016-03-28 14:59:29.072352000    1    8    0.0\n",
      "2016-03-28 14:59:32.152777984    1    8    1.0\n",
      "2016-03-28 14:59:52.983996160    1    8    0.0\n"
     ]
    }
   ],
   "source": [
    "def load_b4(fpath='../local/db/consolidation/bed_2016-03-26.csv', nid=1):\n",
    "    df = pd.read_csv(fpath, names=['timestamp', 'sensor_str', 'value'],\n",
    "                     dtype={'timestamp': np.float64, 'sensor_str': str, 'value': DTYPE_VAL})\n",
    "    df.set_index(df.timestamp.multiply(1e9).astype('datetime64[ns]'), inplace=True)\n",
    "    \n",
    "    temp = df.value.loc[df.sensor_str == 'temp'].resample(FS_VAL).ffill()\n",
    "    strain = df.value.loc[df.sensor_str == 'strain'].resample(FS_VAL).ffill()\n",
    "    motion = df.value.loc[df.sensor_str == 'motion']\n",
    "    df = pd.concat([pd.DataFrame({'sid': sensors[nid]['temp'], 'nid': nid, 'value': temp}),\n",
    "                    pd.DataFrame({'sid': sensors[nid]['strain'], 'nid': nid, 'value': strain}),\n",
    "                    pd.DataFrame({'sid': sensors[nid]['motion'], 'nid': nid, 'value': motion})])\n",
    "    return df\n",
    "\n",
    "%timeit load_b4()\n",
    "print load_b4().tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B5 2016_w13-bed.csv\n",
    "* with header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 18.4 ms per loop\n",
      "                               nid  sid  value\n",
      "timestamp                                     \n",
      "2016-03-30 14:54:27.224745984    1    8    0.0\n",
      "2016-03-30 16:40:03.013702912    1    8    0.0\n",
      "2016-03-30 19:05:10.785732864    1    8    0.0\n"
     ]
    }
   ],
   "source": [
    "def load_b5(fpath='../local/db/consolidation/2016_w13-bed.csv', nid=1):\n",
    "    df = pd.read_csv(fpath, names=['timestamp', 'sensor_str', 'value'], skiprows=1,\n",
    "                     dtype={'timestamp': np.float64, 'sensor_str': str, 'value': DTYPE_VAL})\n",
    "    df.set_index(df.timestamp.multiply(1e9).astype('datetime64[ns]'), inplace=True)\n",
    "    \n",
    "    temp = df.value.loc[df.sensor_str == 'temp']\n",
    "    strain = df.value.loc[df.sensor_str == 'strain'].resample(FS_VAL).ffill()\n",
    "    motion = df.value.loc[df.sensor_str == 'motion']\n",
    "    df = pd.concat([pd.DataFrame({'sid': sensors[nid]['temp'], 'nid': nid, 'value': temp}),\n",
    "                    pd.DataFrame({'sid': sensors[nid]['strain'], 'nid': nid, 'value': strain}),\n",
    "                    pd.DataFrame({'sid': sensors[nid]['motion'], 'nid': nid, 'value': motion})])\n",
    "    return df\n",
    "\n",
    "%timeit load_b5()\n",
    "print load_b5().tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gather chuck telemetry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C1 telemetry.db\n",
    "* slqite3 database\n",
    "* high sampling rate\n",
    "* light, temp, soil, later ds_temp\n",
    "* temp influenced by sun incidence\n",
    "* has sensor meta data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 2.41 s per loop\n",
      "                     nid  sid   value\n",
      "timestamp                            \n",
      "2016-03-28 00:00:00    0    3  440.90\n",
      "2016-03-28 00:30:00    0    3  448.65\n",
      "2016-03-28 01:00:00    0    3  439.90\n"
     ]
    }
   ],
   "source": [
    "def load_c1(fpath='../local/db/consolidation/telemetry.db', nid=0):\n",
    "    with sqlite3.connect(fpath) as con:\n",
    "        df = pd.read_sql_query('SELECT timestamp, type, value FROM telemetry', con)\n",
    "    df.set_index(df.timestamp.multiply(1e9).astype('datetime64[ns]'), inplace=True)\n",
    "    df.columns = ['timestamp', 'sensor_str', 'value']\n",
    "    \n",
    "    temp = df.value.loc[df.sensor_str == sensors[nid]['temp']].resample(FS_VAL).ffill()\n",
    "    ds_temp = df.value.loc[df.sensor_str == sensors[nid]['ds_temp']].resample(FS_VAL).ffill()\n",
    "    light = df.value.loc[df.sensor_str == sensors[nid]['light']].resample(FS_VAL).ffill()\n",
    "    soil = df.value.loc[df.sensor_str == sensors[nid]['soil']].resample('30min').ffill()\n",
    "\n",
    "    df = pd.concat([pd.DataFrame({'sid': sensors[nid]['temp'], 'nid': nid, 'value': temp}),\n",
    "                    pd.DataFrame({'sid': sensors[nid]['ds_temp'], 'nid': nid, 'value': ds_temp}),\n",
    "                    pd.DataFrame({'sid': sensors[nid]['light'], 'nid': nid, 'value': light}),\n",
    "                    pd.DataFrame({'sid': sensors[nid]['soil'], 'nid': nid, 'value': soil})])\n",
    "    return df\n",
    "\n",
    "%timeit load_c1()\n",
    "print load_c1().tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C2 chuck_2016-03-28.csv\n",
    "* new sampling paradigm\n",
    "* ds_temp only, dropped temp for now\n",
    "* no header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 4.75 ms per loop\n",
      "                               nid  sid       value\n",
      "timestamp                                          \n",
      "2016-03-28 19:29:47.512306944    0    3  382.670013\n",
      "2016-03-28 19:59:45.860630016    0    3  384.000000\n",
      "2016-03-28 20:29:44.215078912    0    3  384.329987\n"
     ]
    }
   ],
   "source": [
    "def load_c2(fpath='../local/db/consolidation/chuck_2016-03-28.csv', nid=0):\n",
    "    df = pd.read_csv(fpath, names=['timestamp', 'sensor_str', 'value'],\n",
    "                     dtype={'timestamp': np.float64, 'sensor_str': str, 'value': DTYPE_VAL})\n",
    "    df.set_index(df.timestamp.multiply(1e9).astype('datetime64[ns]'), inplace=True)\n",
    "    \n",
    "    ds_temp = df.value.loc[df.sensor_str == 'ds_temp']\n",
    "    light = df.value.loc[df.sensor_str == 'light']\n",
    "    soil = df.value.loc[df.sensor_str == 'soil']\n",
    "\n",
    "    df = pd.concat([pd.DataFrame({'sid': sensors[nid]['ds_temp'], 'nid': nid, 'value': ds_temp}),\n",
    "                    pd.DataFrame({'sid': sensors[nid]['light'], 'nid': nid, 'value': light}),\n",
    "                    pd.DataFrame({'sid': sensors[nid]['soil'], 'nid': nid, 'value': soil})])\n",
    "    return df\n",
    "\n",
    "%timeit load_c2()\n",
    "print load_c2().tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C3 2016_w13-chuck.csv\n",
    "* with header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 5.41 ms per loop\n",
      "                               nid  sid       value\n",
      "timestamp                                          \n",
      "2016-03-30 23:45:13.574208000    0    3  139.330002\n",
      "2016-03-31 00:15:11.962473216    0    3  134.000000\n",
      "2016-03-31 00:45:10.349884928    0    3  130.330002\n"
     ]
    }
   ],
   "source": [
    "def load_c3(fpath='../local/db/consolidation/2016_w13-chuck.csv', nid=0):\n",
    "    df = pd.read_csv(fpath, names=['timestamp', 'sensor_str', 'value'], skiprows=1,\n",
    "                     dtype={'timestamp': np.float64, 'sensor_str': str, 'value': DTYPE_VAL})\n",
    "    df.set_index(df.timestamp.multiply(1e9).astype('datetime64[ns]'), inplace=True)\n",
    "    \n",
    "    ds_temp = df.value.loc[df.sensor_str == 'ds_temp']\n",
    "    light = df.value.loc[df.sensor_str == 'light']\n",
    "    soil = df.value.loc[df.sensor_str == 'soil']\n",
    "\n",
    "    df = pd.concat([pd.DataFrame({'sid': sensors[nid]['ds_temp'], 'nid': nid, 'value': ds_temp}),\n",
    "                    pd.DataFrame({'sid': sensors[nid]['light'], 'nid': nid, 'value': light}),\n",
    "                    pd.DataFrame({'sid': sensors[nid]['soil'], 'nid': nid, 'value': soil})])\n",
    "    return df\n",
    "\n",
    "%timeit load_c3()\n",
    "print load_c3().tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joining everything up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index    1686944\n",
      "nid       210868\n",
      "sid       210868\n",
      "value     843472\n",
      "dtype: int64\n",
      "nid        uint8\n",
      "sid        uint8\n",
      "value    float32\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "df = pd.concat([load_b2(), load_b3(), load_b4(), load_b5(), load_c1(), load_c2(), load_c3()])\n",
    "df.sid = df.sid.astype(DTYPE_CAT)\n",
    "df.nid = df.nid.astype(DTYPE_CAT)\n",
    "df.value = df.value.astype(DTYPE_VAL)\n",
    "df.sort_index(inplace=True)\n",
    "print df.memory_usage(index=True)\n",
    "print df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store DataFrame to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1721 KiB\n"
     ]
    }
   ],
   "source": [
    "!rm ../local/db/test.h5\n",
    "def store_df(df, fpath='../local/db/telemetry.h5'):\n",
    "    with pd.HDFStore(fpath, complevel=9, complib='blosc') as store:\n",
    "        store.put('data', df, format='table', data_columns=['nid', 'sid'])\n",
    "store_df(df)\n",
    "print os.path.getsize('../local/db/telemetry.h5')/2**10, 'KiB'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~ 200 ms\n",
    "#%timeit pd.read_hdf('../local/db/consolidation/test.h5', 'data', where='sid==1')\n",
    "# ~ 750 ms\n",
    "#df = pd.read_hdf('../local/db/consolidation/test.h5', 'data', where='sid==[1, 2, 3]')\n",
    "# ~ 20 ms\n",
    "#df = pd.read_hdf('../local/db/consolidation/test.h5', 'data')\n",
    "# ~ 5 ms\n",
    "# df = df.loc[df.nid == 0]\n",
    "# ~ 135 ms\n",
    "# df = pd.read_hdf('../local/db/consolidation/test.h5', 'data', where='nid==1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updating from csv sources\n",
    "\n",
    "* rsync new data over\n",
    "* read in both as nodes into DF\n",
    "* check for last timestamp for node in HDF5 file\n",
    "* append delta to HDF5 file\n",
    "* check if the corresponding time frames are identical in csv/hdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "DTYPE_VAL = np.float32\n",
    "DTYPE_CAT = np.uint8\n",
    "nodes = {'chuck': 0, 'bed': 1}\n",
    "sensors = {0: {'temp': 1, 'light': 2, 'soil':3, 'dummy': 4, 'ds_temp':5},\n",
    "           1: {'strain': 6, 'temp': 7, 'motion': 8}}\n",
    "# needed because of the naming overlap in the sensors. [b/c]x are placeholders for debugging.\n",
    "cats = {0: ['c0', 'temp', 'light', 'soil', 'c4', 'ds_temp', 'c6',  'c7'],\n",
    "        1: ['b0', 'b1', 'b2', 'b3', 'b4', 'b5', 'strain',  'temp',  'motion']}\n",
    "\n",
    "def nid_from_filename(fname):\n",
    "    return nodes[os.path.basename(fname).split('-')[-1].split('.')[0]]\n",
    "\n",
    "def load_node_csv(fpath, nid=None):\n",
    "    nid = nid if nid is not None else nid_from_filename(fpath)\n",
    "    df = pd.read_csv(fpath, names=['timestamp', 'sensor_str', 'value'], skiprows=1,\n",
    "                     dtype={'timestamp': np.float64, 'sensor_str': str, 'value': DTYPE_VAL})\n",
    "    df.set_index(df.timestamp.multiply(1e9).astype('datetime64[ns]'), inplace=True)\n",
    "\n",
    "    sid = df.sensor_str.astype('category', categories=cats[nid_from_filename(fpath)]).cat.codes.astype(DTYPE_CAT)\n",
    "    return pd.DataFrame({'sid': sid, 'nid': np.array(nid, dtype=np.uint8), 'value': df.value})\n",
    "\n",
    "def load_hdf(fpath):\n",
    "    return pd.read_hdf(fpath, 'data')\n",
    "\n",
    "def last_samples_hdf(df):\n",
    "    df.sort_index(inplace=True)\n",
    "    assert df.index.is_monotonic\n",
    "    g = df.groupby('nid')\n",
    "    return {k: g.get_group(k).index[-1] for k in [0, 1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "receiving incremental file list\n",
      "2016_w13-chuck.csv\n",
      "\n",
      "sent 1.95K bytes  received 2.88K bytes  3.22K bytes/sec\n",
      "total size is 223.39K  speedup is 46.26\n",
      "receiving incremental file list\n",
      "2016_w13-bed.csv\n",
      "\n",
      "sent 5.37K bytes  received 7.22K bytes  25.17K bytes/sec\n",
      "total size is 784.13K  speedup is 62.30\n"
     ]
    }
   ],
   "source": [
    "!rsync -avh VersedSquid:~/code/telemetry/local/db/2016_w13-chuck.csv ../local/db/\n",
    "!rsync -avh RandyDolphin:~/code/telemetry/local/db/2016_w13-bed.csv ../local/db/\n",
    "    \n",
    "last = last_samples_hdf(load_hdf('../local/db/testing.h5'))\n",
    "node_data = [load_node_csv('../local/db/2016_w13-chuck.csv'), load_node_csv('../local/db/2016_w13-bed.csv')]\n",
    "df = pd.concat([node_data[n][node_data[n].index > last[n]] for n in range(len(node_data))]).sort_index()\n",
    "print df.shape[0], \"new rows to be appended!\"\n",
    "with pd.HDFStore('../local/db/testing.h5') as store:\n",
    "    store.append('data', df, append=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}